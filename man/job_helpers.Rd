% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/jobs.R
\name{job_helpers}
\alias{job_helpers}
\alias{job_get_dir}
\alias{job_sync}
\alias{job_info}
\alias{job_update}
\alias{job_delete}
\alias{job_estimate}
\alias{job_logs}
\alias{job_get_results}
\alias{job_empty_collection}
\title{Manage job artefacts and metadata}
\usage{
job_get_dir(api, user, job_id)

job_sync(api, req, user, job_id)

job_info(api, user, job_id)

job_update(api, user, job_id, job)

job_delete(api, user, job_id)

job_estimate(api, user, job_id)

job_logs(api, user, job_id, offset = 0, level = "info", limit = 10)

job_get_results(api, user, job_id)

job_empty_collection(api, user, job)
}
\arguments{
\item{api}{An openeocraft API object.}

\item{user}{The user identifier associated with the job.}

\item{job_id}{Identifier of the job to operate on.}

\item{req}{A plumber request object representing the incoming call.}

\item{job}{A named list describing a job payload.}

\item{offset}{Zero-based offset when paginating job logs.}

\item{level}{Minimum log level to include, one of \code{"error"}, \code{"warning"},
\code{"info"}, or \code{"debug"}.}

\item{limit}{Maximum number of log records to return.}
}
\value{
\itemize{
\item \code{job_get_dir()} returns the path backing the job workspace.
\item \code{job_sync()} returns \code{NULL} invisibly after updating job status.
\item \code{job_info()} returns a list containing the stored job metadata.
\item \code{job_update()} returns a confirmation list with a status message.
\item \code{job_delete()} returns \code{NULL} invisibly after removing artefacts.
\item \code{job_estimate()} returns a placeholder list describing cost estimates.
\item \code{job_logs()} returns a list with the filtered log entries.
\item \code{job_get_results()} returns either a STAC collection or a placeholder
document when results are pending.
\item \code{job_empty_collection()} returns a minimal STAC collection describing the
job in its current state.
}
}
\description{
Helpers to manage stored jobs, update their status, query logs and results,
and compute derived URLs and documents.
}
